{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20.0\n",
      "1.16.0\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "print(dash.__version__)\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "print(dcc.__version__)\n",
    "import dash_table\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gharbi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gharbi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gharbi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing(text):\n",
    "    \n",
    "    # suppression de pontuation et caracteres numériques\n",
    "    text = re.sub('[^a-zA-Z]',' ', text)\n",
    "    # en lettres minuscules \n",
    "    text = text.lower()\n",
    "    # tokenisation : prendre chaque mot a sa case\n",
    "    text = word_tokenize(text)\n",
    "    # suppression des stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    # Lemmatiser les mots : exemple : Screening => screen , investigated => investigate\n",
    "    lemma = WordNetLemmatizer()\n",
    "    text = [lemma.lemmatize(word=w, pos='v') for w in text]\n",
    "    # supprimer les mots de taille inférieur à 2\n",
    "    text= [i for i in text if len(i) > 2]\n",
    "    # reconvertir en String\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text\n",
    "def search(term, rmax):\n",
    "    Entrez.email = ''\n",
    "    handle = Entrez.esearch(db='pubmed', # DB\n",
    "                            sort='relevance',  # tri par relevance\n",
    "                            retmax=rmax, # combien d'articles\n",
    "                            retmode='xml', \n",
    "                            term=term) # mot clé\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "def fetch_details(id_list):\n",
    "    ids = ','.join(id_list)\n",
    "    Entrez.email = 'your.email@example.com'\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmode='xml',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "    \n",
    "def parse_authors(id_list):\n",
    "    h = Entrez.efetch(db='pubmed', id=id_list, rettype='medline', retmode='text')\n",
    "    records = Medline.parse(h)\n",
    "    authors_list = []\n",
    "    for record in records:\n",
    "        au = record.get('AU', '?')\n",
    "        for a in au: \n",
    "            if a not in authors_list:\n",
    "                authors_list.append(a)\n",
    "    return authors_list\n",
    "\n",
    "def article_date(source):\n",
    "    try :\n",
    "        return source[0]['Year'] + '-' + source[0]['Month'] + '-' + source[0]['Day']\n",
    "    except : return np.nan\n",
    "    \n",
    "def recup(num,terme):\n",
    "    title_list = []\n",
    "    abst_list = []\n",
    "    date_list = []\n",
    "    results = search(terme, num)\n",
    "    #   IDs :\n",
    "    id_list = results['IdList']\n",
    "\n",
    "    papers = fetch_details(id_list)\n",
    "    for i, paper in enumerate(papers['PubmedArticle']):\n",
    "\n",
    "    #       titles : \n",
    "        title = paper['MedlineCitation']['Article']['ArticleTitle']\n",
    "        print(\"{}) {}\".format(i+1, title))\n",
    "        title_list.append(title)\n",
    "\n",
    "    #       Abstracts : \n",
    "        try:\n",
    "            abst = paper['MedlineCitation']['Article']['Abstract']['AbstractText']\n",
    "            abst = str(abst).strip(\"['']\")\n",
    "            abst_list.append(abst)\n",
    "        except:\n",
    "            abst = \"null\"\n",
    "            abst_list.append(abst)\n",
    "\n",
    "    #       Dates : \n",
    "        d = article_date(paper['MedlineCitation']['Article']['ArticleDate'])\n",
    "        date_list.append(d)\n",
    "\n",
    "    #   Authors:\n",
    "    auth_list = []\n",
    "    for id in id_list:\n",
    "        auth = parse_authors(id)\n",
    "        auth_list.append(auth)\n",
    "\n",
    "    for i, abst in enumerate(abst_list):\n",
    "        abst_list[i] = preprocessing(abst)\n",
    "\n",
    "    dict_corpus = {'Article ID' : id_list, 'Titre' : title_list, 'Auteurs': auth_list, 'Date': date_list, 'Abstract' : abst_list}\n",
    "    df_corpus = pd.DataFrame(dict_corpus)\n",
    "\n",
    "    for i,a in enumerate(df_corpus['Auteurs']):\n",
    "        df_corpus['Auteurs'][i] = ', '.join(a)\n",
    "    return df_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorisation_text(text,mindf,maxdf):    \n",
    "    vectorizer = TfidfVectorizer(min_df=mindf,\n",
    "                               max_df=maxdf,\n",
    "                               max_features=None,\n",
    "                               stop_words='english').fit(text)\n",
    "    \n",
    "    X = vectorizer.fit_transform(text)\n",
    "    features = vectorizer.get_feature_names()\n",
    "    return X, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash(__name__,external_stylesheets=[dbc.themes.BOOTSTRAP],prevent_initial_callbacks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = dbc.Row(\n",
    "    [\n",
    "        dbc.Col(\n",
    "                dbc.Input(id=\"num_max\",type=\"number\", placeholder=\"articles numbre\", className=\"mr-3\"),className=\"col-4\"),\n",
    "        dbc.Col(dbc.Input(id =\"word\", type=\"search\", placeholder=\"Covid-19\", className=\"mr-3\"),className=\"col-4\"),\n",
    "        dbc.Col(\n",
    "            dbc.Button(\"recuperer\",id=\"submitt_search\", color=\"success\", className=\"ml-2\"),\n",
    "            width=\"auto\",\n",
    "        ),\n",
    "    ],\n",
    "    no_gutters=True,\n",
    "    className=\"mr-auto flex-nowrap mt-3 mt-md-0\",\n",
    "    align=\"center\",\n",
    "    id=\"navbar_out\"\n",
    ")\n",
    "\n",
    "sidebar = html.Div(\n",
    "    id = \"links\",\n",
    "    className=\"sidebare\",\n",
    "    children =[\n",
    "        dbc.Nav(\n",
    "            [\n",
    "                dbc.Button(\"details fetching\", href=\"/page-1\", active=\"exact\", id='issam'),\n",
    "                dbc.Button(\"Corpus exploitation\",id=\"moh\", href=\"/page-2\", active=\"exact\",n_clicks=0),\n",
    "            ],\n",
    "            vertical=True,\n",
    "            pills=True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "graphe = html.Div(\n",
    "    id='table',\n",
    "     children=[\n",
    "       \n",
    "    ],\n",
    "\n",
    ")\n",
    "information_gen = dbc.Row(\n",
    "\n",
    "\n",
    "    className=\"row\",\n",
    ")\n",
    "visualisation = html.Div(\n",
    "    className=\"content\",\n",
    "    children=[\n",
    "        graphe,\n",
    "        information_gen,\n",
    "        \n",
    "    ]\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "navbar = dbc.Navbar(\n",
    "    [\n",
    "        html.A(\n",
    "            # Use row and col to control vertical alignment of logo / brand\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dbc.NavbarBrand(\"Corpus médical\", className=\"ml-2\")),\n",
    "                ],\n",
    "                align=\"center\",\n",
    "                no_gutters=True,\n",
    "            ),\n",
    "            href=\"https://plot.ly\",\n",
    "        ),\n",
    "        dbc.NavbarToggler(id=\"navbar-toggler\"),\n",
    "        dbc.Collapse(search_bar, id=\"navbar-collapse\", navbar=True),\n",
    "        #no_gutters=True,\n",
    "    ],\n",
    "    color=\"dark\",\n",
    "    dark=True,\n",
    ")\n",
    "\n",
    "page_1_layout = html.Div(\n",
    "    className=\"CONTENT_STYLE\",\n",
    "                  \n",
    "                 children = [\n",
    "                     visualisation\n",
    "                 ]\n",
    "                 \n",
    ")\n",
    "page_2_layout =html.Div(\n",
    "    id=\"layout2\",\n",
    "    children =[dcc.Dropdown(\n",
    "        id='demo-dropdown',\n",
    "        options=[\n",
    "            {'label': 'LDA', 'value': 'lda'},\n",
    "            {'label': 'Co-clustering \" with spherical k-means\"', 'value': 'cokmeans'},\n",
    "            {'label': 'Co-clustering \"with specMod\"', 'value': 'cospecmod'},\n",
    "            {'label': 'Co-clustering \"with Mod\"', 'value': 'comod'}\n",
    "         ]\n",
    "    ),]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = html.Div([dcc.Store(id='storage'),dcc.Location(id=\"url\"), navbar,sidebar,html.Div(id =\"page-content\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add callback for toggling the collapse on small screens\n",
    "@app.callback(\n",
    "    Output(\"navbar-collapse\", \"is_open\"),\n",
    "    [Input(\"navbar-toggler\", \"n_clicks\")],\n",
    "    [State(\"navbar-collapse\", \"is_open\")]\n",
    ")\n",
    "def toggle_navbar_collapse(n,is_open):\n",
    "    if n:\n",
    "        return not is_open\n",
    "    return is_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"table\", \"children\"),\n",
    "    [Input(\"submitt_search\",\"n_clicks\")],\n",
    "    [State('num_max', 'value'),\n",
    "     State('word', 'value'),\n",
    "     State('table','children')]\n",
    ")\n",
    "def fetch(n_clicks,num_max,word,old_output):\n",
    "    df= recup(num_max,word)\n",
    "    return old_output + [dash_table.DataTable(\n",
    "    style_cell={\n",
    "        'whiteSpace': 'normal',\n",
    "        'height': 'auto',\n",
    "    },\n",
    "    style_table={\n",
    "            'width': 950,\n",
    "            'overflowY': 'auto',\n",
    "            'overflowX': 'auto',\n",
    "            'height': 540},\n",
    "    columns=[{\"name\": i, \"id\": i} for i in df.columns],\n",
    "    data=df.to_dict('records'),\n",
    "    export_format=\"csv\",)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(Output('page-content', 'children'),\n",
    "              [Input('url', 'pathname')])\n",
    "def display_page(pathname):\n",
    "    if pathname == '/page-1':\n",
    "        return page_1_layout\n",
    "    elif pathname == '/page-2':\n",
    "        return page_2_layout\n",
    "    else:\n",
    "        return page_index\n",
    "    # You could also return a 404 \"URL not found\" page here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [16/May/2021 20:28:27] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [16/May/2021 20:28:27] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [16/May/2021 20:28:27] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [16/May/2021 20:28:39] \"\u001b[37mGET /_dash-component-suites/dash_table/bundle.js.map HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [16/May/2021 20:28:39] \"\u001b[37mGET /_dash-component-suites/dash_html_components/dash_html_components.min.js.map HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [16/May/2021 20:28:39] \"\u001b[37mGET /_dash-component-suites/dash_core_components/dash_core_components-shared.js.map HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [16/May/2021 20:28:39] \"\u001b[37mGET /_dash-component-suites/dash_core_components/dash_core_components.min.js.map HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.config.suppress_callback_exceptions = True\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
